{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Data from Amazon\n",
    "---\n",
    "In this notebook, we collect the necessary data by scraping it directly from Amazon.\n",
    "\n",
    "The dataset we want:\n",
    "\n",
    "| ID | Review Score | Sales Rank | Category    | Title | Author | Date    | Visual Features     |\n",
    "| -- | ------------ | ---------- | ----------- | ----- | ------ | ------- | ------------------- |\n",
    "\n",
    "The dataset we have, as downloaded from [here](https://github.com/uchidalab/book-dataset):\n",
    "\n",
    "| ID | Filename | Image URL | Title | Author | Category ID | Category |\n",
    "| -- | -------- | --------- | ----- | ------ | ----------- | -------- |\n",
    "\n",
    "The `ID` column in the data can be used to access the webpage of each book, by connecting to https://www.amazon.com/dp/book-id. This allows us to scrape any data that is missing directly from Amazon.\n",
    "\n",
    "We already have the Title, Author and Category of each book ready to be used.\n",
    "\n",
    "For everything else, there's ~~Mastercard~~ BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To request data from Amazon\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# To open image links\n",
    "import urllib\n",
    "\n",
    "# To process data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To extract information from weirdly formatted Amazon info\n",
    "import re\n",
    "\n",
    "# To create random delays to trick the Amazon bot detector\n",
    "from time import sleep\n",
    "import random\n",
    "\n",
    "# To rotate IPs while scraping | WARNING: Don't forget to run `tor` in the terminal before executing this cell\n",
    "from torrequest import TorRequest\n",
    "tor = TorRequest(password='ilovecs401')\n",
    "\n",
    "# To rotate user-agents while scraping\n",
    "from fake_useragent import UserAgent\n",
    "user_agent = UserAgent()\n",
    "\n",
    "# To read data\n",
    "import csv\n",
    "\n",
    "# To check if a file is downloaded already\n",
    "import os\n",
    "\n",
    "# To print an image in the notebook programmatically\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Set data directories\n",
    "ORIGINAL_DATA_DIR = 'Original Data/'\n",
    "COLLECTED_DATA_DIR = 'Collected Data/'\n",
    "IMAGE_DIR = COLLECTED_DATA_DIR + 'Cover Images/'\n",
    "HTML_DIR = '/Users/dogatekin/Data/HTML Files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Original Data\n",
    "---\n",
    "\n",
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Category ID</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761183272</td>\n",
       "      <td>0761183272.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61Y5cOdH...</td>\n",
       "      <td>Mom's Family Wall Calendar 2016</td>\n",
       "      <td>Sandra Boynton</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1623439671</td>\n",
       "      <td>1623439671.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61t-hrSw...</td>\n",
       "      <td>Doug the Pug 2016 Wall Calendar</td>\n",
       "      <td>Doug the Pug</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00O80WC6I</td>\n",
       "      <td>B00O80WC6I.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41X-KQqs...</td>\n",
       "      <td>Moleskine 2016 Weekly Notebook, 12M, Large, Bl...</td>\n",
       "      <td>Moleskine</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>761182187</td>\n",
       "      <td>0761182187.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61j-4gxJ...</td>\n",
       "      <td>365 Cats Color Page-A-Day Calendar 2016</td>\n",
       "      <td>Workman Publishing</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1578052084</td>\n",
       "      <td>1578052084.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51Ry4Tsq...</td>\n",
       "      <td>Sierra Club Engagement Calendar 2016</td>\n",
       "      <td>Sierra Club</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID        Filename  \\\n",
       "0   761183272  0761183272.jpg   \n",
       "1  1623439671  1623439671.jpg   \n",
       "2  B00O80WC6I  B00O80WC6I.jpg   \n",
       "3   761182187  0761182187.jpg   \n",
       "4  1578052084  1578052084.jpg   \n",
       "\n",
       "                                           Image URL  \\\n",
       "0  http://ecx.images-amazon.com/images/I/61Y5cOdH...   \n",
       "1  http://ecx.images-amazon.com/images/I/61t-hrSw...   \n",
       "2  http://ecx.images-amazon.com/images/I/41X-KQqs...   \n",
       "3  http://ecx.images-amazon.com/images/I/61j-4gxJ...   \n",
       "4  http://ecx.images-amazon.com/images/I/51Ry4Tsq...   \n",
       "\n",
       "                                               Title              Author  \\\n",
       "0                    Mom's Family Wall Calendar 2016      Sandra Boynton   \n",
       "1                    Doug the Pug 2016 Wall Calendar        Doug the Pug   \n",
       "2  Moleskine 2016 Weekly Notebook, 12M, Large, Bl...           Moleskine   \n",
       "3            365 Cats Color Page-A-Day Calendar 2016  Workman Publishing   \n",
       "4               Sierra Club Engagement Calendar 2016         Sierra Club   \n",
       "\n",
       "   Category ID   Category  \n",
       "0            3  Calendars  \n",
       "1            3  Calendars  \n",
       "2            3  Calendars  \n",
       "3            3  Calendars  \n",
       "4            3  Calendars  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_names = ['ID', 'Filename', 'Image URL', 'Title', 'Author', 'Category ID', 'Category']\n",
    "\n",
    "books = pd.read_csv(ORIGINAL_DATA_DIR + 'book32-listing.csv', encoding='latin1', header=None, names=header_names)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calendars\n",
      "Comics & Graphic Novels\n",
      "Test Preparation\n",
      "Mystery, Thriller & Suspense\n",
      "Science Fiction & Fantasy\n",
      "Romance\n",
      "Humor & Entertainment\n",
      "Literature & Fiction\n",
      "Gay & Lesbian\n",
      "Engineering & Transportation\n",
      "Cookbooks, Food & Wine\n",
      "Crafts, Hobbies & Home\n",
      "Arts & Photography\n",
      "Education & Teaching\n",
      "Parenting & Relationships\n",
      "Self-Help\n",
      "Computers & Technology\n",
      "Medical Books\n",
      "Science & Math\n",
      "Health, Fitness & Dieting\n",
      "Business & Money\n",
      "Law\n",
      "Biographies & Memoirs\n",
      "History\n",
      "Politics & Social Sciences\n",
      "Reference\n",
      "Christian Books & Bibles\n",
      "Religion & Spirituality\n",
      "Sports & Outdoors\n",
      "Teen & Young Adult\n",
      "Children's Books\n",
      "Travel\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(books['Category'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want the Children's Books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>545790352</td>\n",
       "      <td>0545790352.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51MIi4p2...</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone: The Ill...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419717014</td>\n",
       "      <td>1419717014.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61YgGsg-...</td>\n",
       "      <td>Diary of a Wimpy Kid: Old School</td>\n",
       "      <td>Jeff Kinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423160916</td>\n",
       "      <td>1423160916.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/611CmvkL...</td>\n",
       "      <td>Magnus Chase and the Gods of Asgard, Book 1: T...</td>\n",
       "      <td>Rick Riordan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1476789886</td>\n",
       "      <td>1476789886.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51KqU7Dw...</td>\n",
       "      <td>Rush Revere and the Star-Spangled Banner</td>\n",
       "      <td>Rush Limbaugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1338029991</td>\n",
       "      <td>1338029991.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61kvq74k...</td>\n",
       "      <td>Harry Potter Coloring Book</td>\n",
       "      <td>Scholastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID        Filename  \\\n",
       "0   545790352  0545790352.jpg   \n",
       "1  1419717014  1419717014.jpg   \n",
       "2  1423160916  1423160916.jpg   \n",
       "3  1476789886  1476789886.jpg   \n",
       "4  1338029991  1338029991.jpg   \n",
       "\n",
       "                                           Image URL  \\\n",
       "0  http://ecx.images-amazon.com/images/I/51MIi4p2...   \n",
       "1  http://ecx.images-amazon.com/images/I/61YgGsg-...   \n",
       "2  http://ecx.images-amazon.com/images/I/611CmvkL...   \n",
       "3  http://ecx.images-amazon.com/images/I/51KqU7Dw...   \n",
       "4  http://ecx.images-amazon.com/images/I/61kvq74k...   \n",
       "\n",
       "                                               Title         Author  \n",
       "0  Harry Potter and the Sorcerer's Stone: The Ill...   J.K. Rowling  \n",
       "1                   Diary of a Wimpy Kid: Old School    Jeff Kinney  \n",
       "2  Magnus Chase and the Gods of Asgard, Book 1: T...   Rick Riordan  \n",
       "3           Rush Revere and the Star-Spangled Banner  Rush Limbaugh  \n",
       "4                         Harry Potter Coloring Book     Scholastic  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = books[books['Category'] == \"Children's Books\"].reset_index(drop=True)\n",
    "# We don't need the Category or Category ID columns anymore\n",
    "books.drop(columns=['Category ID', 'Category'], inplace=True)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many books we have left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13605"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's fix the IDs in the dataset. For some reason, the ID column has the leading 0s removed (normally all of them should be 10 characters long), which makes the webpages inaccessible. The filename column has the correct IDs with the correct number of leading 0s. So let's use the Filename column as the new ID column, we can add the `.jpg` extension later when downloading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0545790352</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51MIi4p2...</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone: The Ill...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419717014</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61YgGsg-...</td>\n",
       "      <td>Diary of a Wimpy Kid: Old School</td>\n",
       "      <td>Jeff Kinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423160916</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/611CmvkL...</td>\n",
       "      <td>Magnus Chase and the Gods of Asgard, Book 1: T...</td>\n",
       "      <td>Rick Riordan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1476789886</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51KqU7Dw...</td>\n",
       "      <td>Rush Revere and the Star-Spangled Banner</td>\n",
       "      <td>Rush Limbaugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1338029991</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61kvq74k...</td>\n",
       "      <td>Harry Potter Coloring Book</td>\n",
       "      <td>Scholastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                          Image URL  \\\n",
       "0  0545790352  http://ecx.images-amazon.com/images/I/51MIi4p2...   \n",
       "1  1419717014  http://ecx.images-amazon.com/images/I/61YgGsg-...   \n",
       "2  1423160916  http://ecx.images-amazon.com/images/I/611CmvkL...   \n",
       "3  1476789886  http://ecx.images-amazon.com/images/I/51KqU7Dw...   \n",
       "4  1338029991  http://ecx.images-amazon.com/images/I/61kvq74k...   \n",
       "\n",
       "                                               Title         Author  \n",
       "0  Harry Potter and the Sorcerer's Stone: The Ill...   J.K. Rowling  \n",
       "1                   Diary of a Wimpy Kid: Old School    Jeff Kinney  \n",
       "2  Magnus Chase and the Gods of Asgard, Book 1: T...   Rick Riordan  \n",
       "3           Rush Revere and the Star-Spangled Banner  Rush Limbaugh  \n",
       "4                         Harry Potter Coloring Book     Scholastic  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['ID'] = books['Filename'].apply(lambda row: re.findall(u'(.*).jpg', row)[0])\n",
    "books.drop(columns='Filename', inplace=True)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping New Data\n",
    "---\n",
    "\n",
    "The columns we need to scrape are: `Review Score`, `Sales Rank` and `Date`. We also need to download the images from the URLs so that we can extract visual features from them, completing our dataset. Just in case we need some other information in the future from the webpages, we will also save the raw HTML files so we don't have to scrape them from Amazon again.\n",
    "\n",
    "First we will demonstrate the scraping process for each column on an arbitrary example, then we will combine these in a function and scrape the information for all the books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                                  0545790352\n",
       "Image URL    http://ecx.images-amazon.com/images/I/51MIi4p2...\n",
       "Title        Harry Potter and the Sorcerer's Stone: The Ill...\n",
       "Author                                            J.K. Rowling\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_book = books.iloc[0]\n",
    "example_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Amazon\n",
    "\n",
    "This step is trickier than it sounds. Sending many requests to Amazon servers in quick succession always leads to Captcha pages that check if the request came from a human. In this case, it is indeed not coming from a human so we need to be smarter. We use Tor requests to be able to change our IP at any time and also rotate the User Agent we use to send the request.\n",
    "\n",
    "We also noticed that at least one Tor IP was unable to connect to the servers, so we try the initial request many times with different IPs and user agents until we get a response without any connection errors or getting caught by the bot detector. When a request is successful, we keep using the found IP-agent pair until it fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(book_id, agent=user_agent.random, max_tries=10):\n",
    "    for i in range(max_tries):\n",
    "        try:\n",
    "            # Creating random delays before requests helps to avoid detection\n",
    "            sleep(random.randint(1, 2))\n",
    "            \n",
    "            # Try to connect\n",
    "            response = tor.get('https://www.amazon.com/dp/' + book_id, headers={'User-Agent': agent})\n",
    "            status = response.status_code\n",
    "            \n",
    "            # Check if page still exists\n",
    "            if(status != 200):\n",
    "                return status, None, agent, None\n",
    "            \n",
    "            # Make soup if we didn't get any errors\n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "            \n",
    "            # If we get redirected to a Captcha page raise error to try again\n",
    "            if(soup.title.string == 'Robot Check'):\n",
    "                raise ConnectionError\n",
    "            \n",
    "            # If we successfully reach the webpage, return the soup, successful agent and raw HTML\n",
    "            return status, soup, agent, response.text\n",
    "        \n",
    "        except ConnectionError:\n",
    "            # If something is wrong with the IP, get a new IP and user agent and try again\n",
    "            tor.reset_identity()\n",
    "            agent = user_agent.random\n",
    "            print(f'Trial {i+1} failed to connect for book ID {book_id}, resetting IP and trying again.', end='\\r')\n",
    "    \n",
    "    raise ConnectionError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it on our example book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Harry Potter and the Sorcerer's Stone: The Illustrated Edition (Harry Potter, Book 1): J.K. Rowling, Jim Kay: 9780545790352: Amazon.com: Books\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, soup, _, _ = connect(example_book['ID'])\n",
    "soup.title.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Rank and Date\n",
    "\n",
    "We can get both of these from the product details table on the webpage, which is in a table conveniently named `productDetailsTable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>Age Range:</b>,\n",
       " <b>Grade Level:</b>,\n",
       " <b>Series:</b>,\n",
       " <b>Hardcover:</b>,\n",
       " <b>Publisher:</b>,\n",
       " <b>Language:</b>,\n",
       " <b>ISBN-10:</b>,\n",
       " <b>ISBN-13:</b>,\n",
       " <b>\n",
       "     Product Dimensions: \n",
       "     </b>,\n",
       " <b>Shipping Weight:</b>,\n",
       " <b>Average Customer Review:</b>,\n",
       " <b>Amazon Best Sellers Rank:</b>,\n",
       " <b><a href=\"https://www.amazon.com/gp/bestsellers/books/3153/ref=pd_zg_hrsr_books_1_5_last/134-2712085-9861750\">Friendship</a></b>,\n",
       " <b><a href=\"https://www.amazon.com/gp/bestsellers/books/2967/ref=pd_zg_hrsr_books_2_3_last/134-2712085-9861750\">Action &amp; Adventure</a></b>,\n",
       " <b><a href=\"https://www.amazon.com/gp/bestsellers/books/3017/ref=pd_zg_hrsr_books_3_4_last/134-2712085-9861750\">Fantasy &amp; Magic</a></b>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('#productDetailsTable li b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use regex to extract the info we need from the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales Rank: 124\n",
      "Date: October 6, 2015\n"
     ]
    }
   ],
   "source": [
    "for li in soup.select('#productDetailsTable li'):\n",
    "    # We only need two of the list items\n",
    "    if(li.b.string == 'Amazon Best Sellers Rank:'):\n",
    "        # The rank is given in the format #1,234,567\n",
    "        sales_rank = re.findall(u'#([\\d,]+)', li.b.nextSibling)[0]\n",
    "    elif(li.b.string == 'Publisher:'):\n",
    "        # The date is in the last set of parantheses\n",
    "        date = re.findall(u'\\(([^\\(\\)]*)\\)$', li.b.nextSibling)[0]\n",
    "        \n",
    "print(f'Sales Rank: {sales_rank}\\nDate: {date}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn it into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rank_date(soup):\n",
    "    # Initial values to return if cannot be scraped\n",
    "    sales_rank = date = None\n",
    "    \n",
    "    for li in soup.select('#productDetailsTable li'):\n",
    "        if(li.b.string == 'Amazon Best Sellers Rank:'):\n",
    "            try:\n",
    "                sales_rank = re.findall(u'#([\\d,]+)', li.b.nextSibling)[0]  # Format: #1,234,567\n",
    "                sales_rank = int(sales_rank.replace(',',''))  # Remove the commas and convert to integer\n",
    "            except:\n",
    "                sales_rank = None  # couldn't scrape\n",
    "        elif(li.b.string == 'Publisher:'):\n",
    "            try:\n",
    "                date = re.findall(u'\\(([^\\(\\)]*)\\)$', li.b.nextSibling)[0]  # Format: Inside last parantheses\n",
    "            except:\n",
    "                date = None  # couldn't scrape\n",
    "                \n",
    "    return sales_rank, date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try on example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 'October 6, 2015')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_rank_date(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Score\n",
    "\n",
    "You might have noticed there is also an item called `Average Customer Review` in the table we just used to extract the Rank and Date. Inside that item, all the review scores are found in a table with the id `histogramTable`, that gives the percentages of users for each score from 1 to 5 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 star87%4 star8%3 star2%2 star1%1 star2%'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = soup.select('#histogramTable')[0].text\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formatting is not great, but it's nothing we can't fix by using a simple regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5', '87'), ('4', '8'), ('3', '2'), ('2', '1'), ('1', '2')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = re.findall(u'(\\d) star(\\d+)%', reviews)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted average of these scores is our final Review Score for the given book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.77"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 0\n",
    "for pair in reviews:\n",
    "    score += int(pair[0]) * int(pair[1])/100  # weights are percentages\n",
    "\n",
    "round(score, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_score(soup):\n",
    "    # Initial value to return if cannot be scraped\n",
    "    score = None\n",
    "    \n",
    "    try:\n",
    "        reviews = soup.select('#histogramTable')[0].text\n",
    "        reviews = re.findall(u'(\\d) star(\\d+)%', reviews)\n",
    "\n",
    "        score = 0\n",
    "        for pair in reviews:\n",
    "            score += int(pair[0]) * int(pair[1])/100  # weights are percentages\n",
    "\n",
    "        score = round(score, 3)\n",
    "    except:\n",
    "        score = None  # couldn't scrape\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try on example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.77"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_score(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cover Image\n",
    "\n",
    "The image URL of each book is available in the original dataset, let's make a HashMap of `ID:URL` pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0545790352': 'http://ecx.images-amazon.com/images/I/51MIi4p2YyL.jpg',\n",
       " '1419717014': 'http://ecx.images-amazon.com/images/I/61YgGsg-k-L.jpg',\n",
       " '1423160916': 'http://ecx.images-amazon.com/images/I/611CmvkLO4L.jpg',\n",
       " '1476789886': 'http://ecx.images-amazon.com/images/I/51KqU7Dw9SL.jpg',\n",
       " '1338029991': 'http://ecx.images-amazon.com/images/I/61kvq74kVSL.jpg'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = books[['ID', 'Image URL']].set_index('ID').to_dict()['Image URL']\n",
    "\n",
    "# Show random 5 mappings\n",
    "dict(list(urls.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it on our example book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://ecx.images-amazon.com/images/I/51MIi4p2YyL.jpg'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_url = urls[example_book['ID']]\n",
    "example_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![Example Image](http://ecx.images-amazon.com/images/I/51MIi4p2YyL.jpg)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(f'![Example Image]({example_url})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn it into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(book_id):\n",
    "    url = urls[book_id]\n",
    "    filename = book_id + '.jpg'\n",
    "    \n",
    "    # Download only if not already downloaded\n",
    "    if not os.path.isfile(IMAGE_DIR + filename):\n",
    "        downloaded_img = urllib.request.urlopen(url)\n",
    "        f = open(IMAGE_DIR + filename, mode='wb')\n",
    "        f.write(downloaded_img.read())\n",
    "        downloaded_img.close()\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw HTML\n",
    "\n",
    "Save the raw HTML files so we don't have to scrape them from Amazon again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(book_id, html_text):\n",
    "    filename = book_id + '.html'\n",
    "    \n",
    "    # Save only if not already saved\n",
    "    if not os.path.isfile(HTML_DIR + filename):\n",
    "        html_file = open(HTML_DIR + filename,\"w\")\n",
    "        html_file.write(html_text)\n",
    "        html_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing it together\n",
    "\n",
    "Let's bring all of the functions we created together under one function that will connect to the webpage, scrape all the necessary info, download the cover image and save the HTML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_info(book_id, agent=user_agent.random):\n",
    "    try:\n",
    "        # Connect to Amazon, keep track of agent\n",
    "        status, soup, current_agent, raw_html = connect(book_id, agent)\n",
    "\n",
    "        if(status == 200):\n",
    "            # Save the HTML file\n",
    "            save_html(book_id, raw_html)\n",
    "\n",
    "            # Get sales rank and date\n",
    "            sales_rank, date = extract_rank_date(soup)\n",
    "\n",
    "            # Get average review score\n",
    "            score = extract_score(soup)\n",
    "\n",
    "            # Download cover image\n",
    "            download_image(book_id)\n",
    "        else:\n",
    "            # Log the error\n",
    "            sales_rank = date = score = f'Error {status}'\n",
    "        \n",
    "    except ConnectionError:\n",
    "        current_agent = agent\n",
    "        sales_rank = date = score = None\n",
    "        \n",
    "    return current_agent, book_id, sales_rank, date, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a final test on the example book we used above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0545790352', 132, 'October 6, 2015', 4.77)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped = scrape_info(example_book['ID'])\n",
    "scraped[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing the dataset\n",
    "---\n",
    "\n",
    "To be able to stop and continue at will, we will write the scraped info to a csv file as we go along, and simultaneously download cover images. Let's initialize this file with a meaningful header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(COLLECTED_DATA_DIR + 'scraped.csv', 'a') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['ID', 'Sales Rank', 'Date', 'Review Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go through the dataset, starting scraping from where we last left off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping stopped by manual interruption. Check the last downloaded book cover image and the last row of the CSV file to make sure there were no corruptions. Total number of books scraped until interruption: 710.\n"
     ]
    }
   ],
   "source": [
    "with open(COLLECTED_DATA_DIR + 'scraped.csv', 'a+') as file:\n",
    "    reader = csv.reader(file)\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Look at the last scraped book to continue from the next one in the dataset\n",
    "    file.seek(0)\n",
    "    last_scraped = next(reversed(list(reader)))[0]\n",
    "    \n",
    "    if(last_scraped == 'ID'):\n",
    "        # Nothing was scraped yet, start from the beginning\n",
    "        index = 0\n",
    "    else:\n",
    "        # At least one book was scraped, find the index of the last scraped book and start from the next one\n",
    "        last_scraped_index = books.index[books['ID'] == last_scraped].tolist()[0]\n",
    "        index = last_scraped_index + 1\n",
    "     \n",
    "    try:\n",
    "        agent = user_agent.random\n",
    "        count = 0    \n",
    "        while(index < books.shape[0]):\n",
    "            current_id = books.iloc[index]['ID']\n",
    "            scraped = scrape_info(current_id, agent)\n",
    "\n",
    "            # Keep track of agent\n",
    "            agent = scraped[0]\n",
    "\n",
    "            writer.writerow(scraped[1:])\n",
    "            file.flush()\n",
    "\n",
    "            index += 1\n",
    "            count += 1\n",
    "\n",
    "            # Clean the previous line while printing info about scraping progress\n",
    "            print(f'Number of scraped books: {count}                                                     ', end='\\r')\n",
    "    except KeyboardInterrupt:\n",
    "        print(f'Scraping stopped by manual interruption. Check the last downloaded book cover image and the last row of the CSV file to make sure there were no corruptions. Total number of books scraped until interruption: {count}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Collected Data\n",
    "---\n",
    "\n",
    "Now that we have the data collected, we should make sure it's clean before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sales Rank</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0545790352</td>\n",
       "      <td>118</td>\n",
       "      <td>October 6, 2015</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419717014</td>\n",
       "      <td>399</td>\n",
       "      <td>November 3, 2015</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1423160916</td>\n",
       "      <td>9637</td>\n",
       "      <td>October 6, 2015</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1476789886</td>\n",
       "      <td>5439</td>\n",
       "      <td>October 27, 2015</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1338029991</td>\n",
       "      <td>196</td>\n",
       "      <td>November 10, 2015</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID Sales Rank               Date Review Score\n",
       "0  0545790352        118    October 6, 2015         4.77\n",
       "1  1419717014        399   November 3, 2015          4.8\n",
       "2  1423160916       9637    October 6, 2015          4.6\n",
       "3  1476789886       5439   October 27, 2015          4.9\n",
       "4  1338029991        196  November 10, 2015         4.61"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Collected Data/scraped.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many books we currently have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4694, 4)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there were unreachable webpages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sales Rank</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>1507745923</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1423160657</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>151206212X</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>0375848134</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>1846432065</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590</th>\n",
       "      <td>1494431726</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "      <td>Error 404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID Sales Rank       Date Review Score\n",
       "237   1507745923  Error 404  Error 404    Error 404\n",
       "510   1423160657  Error 404  Error 404    Error 404\n",
       "2566  151206212X  Error 404  Error 404    Error 404\n",
       "3738  0375848134  Error 404  Error 404    Error 404\n",
       "4119  1846432065  Error 404  Error 404    Error 404\n",
       "4590  1494431726  Error 404  Error 404    Error 404"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Sales Rank'] == 'Error 404']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a few, these are most likely Amazon listings that do not exist anymore (e.g. the book might not be on sale anymore). We can drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Sales Rank'] != 'Error 404']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which of the rows have missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sales Rank</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0545703301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0545561639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1570548307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>054549284X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0545561663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID Sales Rank Date Review Score\n",
       "43   0545703301        NaN  NaN         4.23\n",
       "163  0545561639        NaN  NaN         4.29\n",
       "175  1570548307        NaN  NaN         4.77\n",
       "198  054549284X        NaN  NaN         4.68\n",
       "203  0545561663        NaN  NaN         4.34"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = data[data['Sales Rank'].isna() | data['Date'].isna() | data['Review Score'].isna()]\n",
    "missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(873, 4)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might seem like a big number at first, but presumably most of these are here because we left the scraper running for a while without handling the Captcha pages. Let's confirm this; those rows where the scraper was blocked would have NaN for all three columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sales Rank</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0062233009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>0753456095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>0439903742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0399256059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>1770496459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID Sales Rank Date Review Score\n",
       "835  0062233009        NaN  NaN          NaN\n",
       "839  0753456095        NaN  NaN          NaN\n",
       "843  0439903742        NaN  NaN          NaN\n",
       "844  0399256059        NaN  NaN          NaN\n",
       "847  1770496459        NaN  NaN          NaN"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocked = data[data['Sales Rank'].isna() & data['Date'].isna() & data['Review Score'].isna()]\n",
    "blocked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 4)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we guessed, most of the missing data seems to be because of this reason. We fixed the Captcha issue after a while, so these missing values should be isolated to a single part of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835 - 2016\n"
     ]
    }
   ],
   "source": [
    "print(min(blocked.index), '-', max(blocked.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms our hypothesis, the bot detector started being suspicious around the 800th book and blocked more and more requests until the 2016th book, after which we handled the bot detection issue.\n",
    "\n",
    "We will drop these for this milestone and collect the data we missed later on. What about the other rows where only some of the columns are missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sales Rank</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0545703301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0545561639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1570548307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>054549284X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0545561663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0545459907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>159174802X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0060245867</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>B005SN42LM</td>\n",
       "      <td>4793006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>0807588997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>0807588970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>0742403890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>0439079470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>1862085323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>October 12, 1997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>1404270809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August 30, 2006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>1433971275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August 1, 2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>B008647VN6</td>\n",
       "      <td>2256782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>0439916178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>April 1, 2007</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID Sales Rank              Date Review Score\n",
       "43    0545703301        NaN               NaN         4.23\n",
       "163   0545561639        NaN               NaN         4.29\n",
       "175   1570548307        NaN               NaN         4.77\n",
       "198   054549284X        NaN               NaN         4.68\n",
       "203   0545561663        NaN               NaN         4.34\n",
       "221   0545459907        NaN               NaN         4.61\n",
       "233   159174802X        NaN               NaN         4.67\n",
       "300   0060245867         24               NaN          4.7\n",
       "434   B005SN42LM    4793006               NaN          4.5\n",
       "2046  0807588997        NaN               NaN         4.59\n",
       "2216  0807588970        NaN               NaN         4.48\n",
       "2680  0742403890        NaN               NaN         3.57\n",
       "2856  0439079470        NaN               NaN          4.6\n",
       "4108  1862085323        NaN  October 12, 1997            0\n",
       "4110  1404270809        NaN   August 30, 2006            0\n",
       "4111  1433971275        NaN    August 1, 2012            0\n",
       "4118  B008647VN6    2256782               NaN          4.0\n",
       "4156  0439916178        NaN     April 1, 2007          4.3"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = missing.drop(blocked.index)\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at a bunch of these listings on Amazon, we see that the missing values are simply not given on their webpages. That is, they don't have a sales rank and/or their publishing date is not written. For the initial analysis in this milestone, we drop these as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some statistics *before* turning our columns into their respective types to see the number of unique values in each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sales Rank</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3815</td>\n",
       "      <td>3815</td>\n",
       "      <td>3815</td>\n",
       "      <td>3815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3815</td>\n",
       "      <td>3786</td>\n",
       "      <td>1631</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>030798155X</td>\n",
       "      <td>479</td>\n",
       "      <td>August 25, 2015</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID Sales Rank             Date Review Score\n",
       "count         3815       3815             3815         3815\n",
       "unique        3815       3786             1631          164\n",
       "top     030798155X        479  August 25, 2015          5.0\n",
       "freq             1          3               33          203"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = data.describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplicated sales ranks are interesting because we would expect each ranking to be unique; we should look into that. For example, let's look at the top one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sales Rank</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0763644765</td>\n",
       "      <td>479</td>\n",
       "      <td>September 14, 2010</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1554537045</td>\n",
       "      <td>479</td>\n",
       "      <td>April 1, 2014</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>0786807601</td>\n",
       "      <td>479</td>\n",
       "      <td>March 5, 2001</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID Sales Rank                Date Review Score\n",
       "28    0763644765        479  September 14, 2010          4.6\n",
       "126   1554537045        479       April 1, 2014         4.61\n",
       "3950  0786807601        479       March 5, 2001         4.83"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = clean[clean['Sales Rank'] == desc['Sales Rank']['top']]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to investigate is to scrape their ranks again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28      497\n",
       "126     465\n",
       "3950    452\n",
       "dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates.apply(lambda row: extract_rank_date(connect(row['ID'])[1])[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sales ranks on Amazon can change very easily over time as millions of users buy items every second. We see that these books are quite close to the Sales Rank values they have in our data but all of them have changed slightly.\n",
    "\n",
    "Since the scraping is not done all at once and since the rankings keep changing, it is understandable that multiple books that have comparable sales have the same ranking at the time we scrape them. We decided that this is not a problem at this point.\n",
    "\n",
    "We should now make all the columns the correct type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID              object\n",
       "Sales Rank      object\n",
       "Date            object\n",
       "Review Score    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales rank and review score can be converted to numerical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sales Rank'] = pd.to_numeric(data['Sales Rank'])\n",
    "data['Review Score'] = pd.to_numeric(data['Review Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Date column could also be converted into datetime, but we have to keep in mind that we don't have all the date information for each book. For some of them we have all of day, month and year; for some we only have month and year; for others we only have the year. So when we convert, we will see the first day of the month for the ones we don't have day data and we will see the first of January for the ones we don't have day or month data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the statistics again to get more meaningful information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales Rank</th>\n",
       "      <th>Review Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.815000e+03</td>\n",
       "      <td>3815.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.291614e+05</td>\n",
       "      <td>4.409151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.703563e+06</td>\n",
       "      <td>0.972710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.236350e+04</td>\n",
       "      <td>4.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.003380e+05</td>\n",
       "      <td>4.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.742715e+05</td>\n",
       "      <td>4.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.754868e+07</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sales Rank  Review Score\n",
       "count  3.815000e+03   3815.000000\n",
       "mean   6.291614e+05      4.409151\n",
       "std    1.703563e+06      0.972710\n",
       "min    2.200000e+01      0.000000\n",
       "25%    2.236350e+04      4.450000\n",
       "50%    1.003380e+05      4.660000\n",
       "75%    4.742715e+05      4.790000\n",
       "max    1.754868e+07      5.000000"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numerical features\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2015-08-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>1940-09-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2018-01-30 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date\n",
       "count                  3815\n",
       "unique                 1603\n",
       "top     2015-08-25 00:00:00\n",
       "freq                     33\n",
       "first   1940-09-01 00:00:00\n",
       "last    2018-01-30 00:00:00"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Date\n",
    "data.describe(include=np.datetime64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have books all the way from 1940 to early this year!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
